#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import numpy as np

get_ipython().run_line_magic('matplotlib', 'inline')
import matplotlib.pyplot as plt

import seaborn as sns


# In[2]:


housing = pd.read_csv('data.csv')


# In[3]:


housing.head()


# In[4]:


housing.info()


# In[5]:


housing['CHAS'].value_counts()


# In[6]:


housing.describe()


# In[7]:


housing.hist(bins=50, figsize=(20,15))


# ## Train Test Spliting

# This bellow function takes a dataset and a test ratio as inputs, shuffles the dataset, and then splits it into training and testing sets based on the given ratio. The shuffling ensures that the data is randomly distributed between the training and test sets

# In[8]:


# JUST FOR LEARNING PURPOSE

def split_train_test(data, test_ratio):
    np.random.seed(42)
    # Calculate the number of elements in the dataset and create a randomly permuted sequence of indices
    shuffled = np.random.permutation(len(data))
    # print(shuffled)
    # Determine the number of test samples based on the given test ratio
    test_set_size = int(len(data) * test_ratio)
    
    # Select the first 'test_set_size' indices for the test set
    test_indices = shuffled[:test_set_size]
    
    # Select the remaining indices for the training set
    train_indices = shuffled[test_set_size:]
    
    # Return the data split into training and testing sets using the calculated indices
    return data.iloc[train_indices], data.iloc[test_indices]


# In[9]:


# train_set, test_set = split_train_test(housing, 0.2)


# In[10]:


# print(f"Rows in train set: {len(train_set)}\nRows in test set: {len(test_set)}")


# In[11]:


from sklearn.model_selection import train_test_split
train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)
print(f"Rows in train set: {len(train_set)}\nRows in test set: {len(test_set)}")


# ### StraightifiedShuffleSplit
# 
# * **Purpose**: Stratified sampling ensures that the train and test sets are representative of the overall population. This is particularly useful when dealing with imbalanced datasets or when certain features (like CHAS in this case) have a significant impact on the target variable.
# 
# ##### Setting Parameters:
# 
# * **n_splits=1**    :    We only want to create one pair of train/test sets.
# * **test_size=0.2** : 20% of the data is set aside for the test set, and 80% is used for training.
# * **random_state=42**: A fixed seed value for reproducibility of results.
# 
# 
# ##### Generating Splits:
# 
# The split.split(housing, housing['CHAS']) method generates indices for the train and test sets, ensuring that the CHAS feature's distribution is preserved in both sets.
# 
# 

# In[12]:


# Import the StratifiedShuffleSplit class from sklearn.model_selection
from sklearn.model_selection import StratifiedShuffleSplit

# Create an instance of StratifiedShuffleSplit with 1 split, 20% test size, and a fixed random seed for reproducibility
split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)

# Iterate over the splits generated by the StratifiedShuffleSplit instance
# split.split(housing, housing['CHAS']) returns the train and test indices ensuring the 'CHAS' column distribution is preserved
for train_index, test_index in split.split(housing, housing['CHAS']):
    # Create the training set using the train indices
    strat_train_set = housing.loc[train_index]
    # Create the test set using the test indices
    strat_test_set = housing.loc[test_index]


# In[13]:


strat_test_set['CHAS'].value_counts()


# In[14]:


strat_train_set['CHAS'].value_counts()


# In[15]:


95/7


# In[16]:


376/28


# What you get it from above value counts and **StratifiedShuffleSplit** ?
# its shows us that how StratifiedShuffleSplit suffle and disrtibuted data equal sampling in train and test. So always try to check it out when you are spliting your data. show equal ratio in train and test. 
# 
# ##### before model building confirm about the sampling distribution or check the ratio of your data is correct or not.

# In[17]:


housing = strat_train_set.copy()


# ### Looking for correlations
# 
# 
# 
# 
# note : always check out the documentation of function you are using. it will clear more conceptsn and also you understand from which library it is from.
# like here **.corr()**.
# 
# 
# 
# ## what is correlatio coefficient of pearson?
# 
# The Pearson correlation coefficient is aÂ [descriptive statistic](https://www.scribbr.com/statistics/descriptive-statistics/), meaning that it summarizes the characteristics of a dataset. Specifically, it describes the strength and direction of the linear relationship between two quantitative variables.

# In[18]:


corr_matrix = housing.corr()
corr_matrix['MEDV'].sort_values(ascending = False)


# In[19]:


from pandas.plotting import scatter_matrix

attributes = ["MEDV", "RM", "ZN", "LSTAT"]
scatter_matrix(housing[attributes], figsize=(12,8))


# In[20]:


housing.plot(kind='scatter', x='RM', y = 'MEDV', alpha=0.8)


# As you see the correlation of "RM" with "MEDV". here i see many outliers. this power of scatterplot. because RM has Highly Strong correlated with target variable. if we handle these outlier and then pass the data to our model. it will be show more best result without outliers. our model will not confused with these outliers.
# 
# 
# Second point : here you can see that RM values is caped in 50. when rooms are 5 it has 50lac value and where 9 rooms its also price is 5lac. It should have been that where the rooms are five, the values will less, and where there are nine rooms, the price will higher then five rooms not be equiled. so here is recommendation that we can talk to our client. 

# In[21]:


housing.plot(kind='scatter', x='LSTAT', y = 'MEDV', alpha=0.7)


# ## Trying out ATTRIBUTE COMBINATION

# In[22]:


housing['TAXRM'] = housing['TAX']/housing['RM']


# In[23]:


housing.head()


# In[24]:


296/6.575


# In[25]:


corr_matrix['MEDV'].sort_values(ascending = False)


# In[26]:


housing.plot(kind='scatter', x='TAXRM', y = 'MEDV', alpha=0.8)


# In[27]:


housing = strat_train_set.drop("MEDV", axis=1)
housing_labels = strat_train_set["MEDV"].copy()


# ## Missing Attributes
# 
# if your missing values in any feature which high correlated to target variable then you didnt get rid off the missing values or attributes. you have to figured out how you can fill the missing value.

# In[28]:


median = housing['RM'].median()


# In[29]:


median


# In[30]:


housing['RM'].fillna(median)


# In[31]:


housing.shape


# In[32]:


from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy = 'median')
imputer.fit(housing)


# In[33]:


imputer.statistics_


# In[34]:


imputer.statistics_.shape # it mean Simpleimputer calculate median values of all 15 features


# In[35]:


X = imputer.transform(housing)


# In[36]:


housing_tr = pd.DataFrame(X, columns = housing.columns)


# In[37]:


housing_tr.describe()


# ## Scikit-learn Design

# Primarily, three types of objects
# 1. Estimators - It estimates some parameter based on a dataset. Eg. imputer. It has a fit method and transform method. Fit method - Fits the dataset and calculates internal parameters
# 
# 2. Transformers - transform method takes input and returns output based on the learnings from fit(). It also has a convenience function called fit_transform() which fits and then transforms.
# 
# 3. Predictors - LinearRegression model is an example of predictor. fit() and predict() are two common functions. It also gives score() function which will evaluate the predictions. 

# ## Feature Scaling

# Primarily, two types of feature scaling methods:
# 1. Min-max scaling (Normalization)
#     (value - min)/(max - min)
#     Sklearn provides a class called MinMaxScaler for this
#     
# 2. Standardization
#     (value - mean)/std
#     Sklearn provides a class called StandardScaler for this
# 

# ## Creating a Pipeline

# In[38]:


from sklearn.pipeline import Pipeline # Pipelilne automate things
from sklearn.preprocessing import StandardScaler
my_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy = 'median')),
    # .... add as manu as you want in your pipeline
    ('std_scaler', StandardScaler()),
])


# In[39]:


housing_num_tr = my_pipeline.fit_transform(housing) # we use housing becuase on housing_tr we already applied many methods


# In[40]:


housing_num_tr


# In[41]:


housing_num_tr.shape


# ## Selecting a desired model for Dragon Real Estates

# In[42]:


from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
# model = LinearRegression()
# model = DecisionTreeRegressor()
model = RandomForestRegressor()
model.fit(housing_num_tr, housing_labels)


# In[43]:


some_data = housing.iloc[:5]


# In[44]:


some_labels = housing_labels.iloc[:5]


# In[45]:


prepared_data = my_pipeline.transform(some_data)


# In[46]:


model.predict(prepared_data)


# In[47]:


list(some_labels)


# ## Evaluating the model

# In[48]:


from sklearn.metrics import mean_squared_error
housing_predictions = model.predict(housing_num_tr)
mse = mean_squared_error(housing_labels, housing_predictions)
rmse = np.sqrt(mse)


# In[49]:


rmse


# As see in DecisionRegressor our model is overfitted because our model wont learn trend it learned noise of data.
# 
# now when ever our mse result show zero. it mean our model was overfited now.
# for handling over fitting we are going to use better evaluation technique -- **Cross Validation**.

# ## Using better Evaluation Technique - Cross Validation

# In[50]:


# 1 2 3 4 5 6 7 8 9 10
from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, housing_num_tr, housing_labels, scoring="neg_mean_squared_error", cv=10)
rmse_score = np.sqrt(-scores)


# In[51]:


rmse_score


# In[52]:


def print_scores(scores):
    print("scores: ", scores)
    print("Mean: ", scores.mean())
    print("Standard deviation: ", scores.std())


# In[53]:


print_scores(rmse_score)


# ## Saving the model

# In[54]:


from joblib import dump, load
dump(model, 'Dragon.joblib')


# ## Testing the model on Test Data

# In[55]:


X_test = strat_test_set.drop('MEDV', axis = 1)
Y_test = strat_test_set["MEDV"].copy()
X_test_prepared = my_pipeline.transform(X_test)
final_predictions = model.predict(X_test_prepared)
final_mse = mean_squared_error(Y_test, final_predictions)
final_rmse = np.sqrt(final_mse) 


# In[56]:


final_rmse


# In[58]:


print(final_predictions, list(Y_test))


# In[60]:


prepared_data[0]


# ## Using the model

# In[61]:


from joblib import dump, load
import numpy as np
model = load('Dragon.joblib')

inputs = np.array([[-0.43942006,  4.12628155, -1.13165014, -0.27288841, -1.62262747,
       -10.23979304, -10.31238772,  2.61111401, -1.0016859 , -0.5778192 ,
       -0.997491834,  0.41164221, -0.86091034]])
model.predict(inputs)
 

